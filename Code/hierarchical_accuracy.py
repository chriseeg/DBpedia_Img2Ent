# -*- coding: utf-8 -*-
"""Hierarchical Accuracy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19zk-9oi9gZ4JLw2in9AVez2-lBzurpRZ

Calculate predictions based on the hierarchy of dbo_classes.

#Initalization
"""

!pip install gcsfs
import threading, re, sys, os, time, csv, requests, random, json, tempfile, math, itertools, google.auth, urllib.request, gcsfs
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from urllib.request import urlopen 
from six.moves.urllib.request import urlopen
from lxml import html
from bs4 import BeautifulSoup
from google.colab import drive
from google.cloud import storage
from google.colab import auth
from datetime import datetime
from sklearn.metrics import confusion_matrix,accuracy_score,f1_score

#Define locations & mount Google Drive
directory = "drive/My Drive/ISE/dbo Classes/"
drive.mount("drive", force_remount=True)

#Authentication & initialization Google Cloud
auth.authenticate_user()

with open('/content/adc.json', 'r') as f:
  auth_info = json.load(f)
credentials, project = google.auth.default()

client = storage.Client(credentials=credentials, project='ise-project-259623')
fs = gcsfs.GCSFileSystem(project='ise-project-259623')
bucket = client.get_bucket('ise-bucket')

"""#Functions

Lists used for hierarchy calculation

- List of hierarchies

Mappings:
- c_names: classification label index -> name
- h_names: hierarchy list index -> name
- c2h_index_map: classification label index -> hierarchy list index 
- h2c_index_map: hierarchy list index -> classification label index
"""

def csv_to_list(path):
  with open(path, 'r') as f:
    reader = csv.reader(f)
    return list(reader)

def csv_to_list_gcs(path):
  with fs.open(path, 'r') as f:
    reader = csv.reader(f)
    return list(reader)

def tsv_to_list(path):
  with open(path, 'r') as f:
    reader = csv.reader(f,delimiter="\t")
    return list(reader)

def tsv_to_list_single(path):
  with open(path, 'r') as f:
    reader = csv.reader(f,delimiter="\t")
    result = [line[0] for line in list(reader)]
    return result

def load_files(config):
  hierarchies_raw = csv_to_list_gcs('gs://ise-bucket/efficientnet/hierarchy_lists/dbo classes hierarchies.csv')
  classification_labels_mapping = csv_to_list_gcs('gs://ise-bucket/efficientnet/configs/{}/labels_map.csv'.format(config))

  #remove empty cells from hierarchy csv
  hierarchies = [[i for i in line if i != ''] for line in hierarchies_raw]

  #get c_names from classification_labels_mapping
  c_names = [line[0] for line in classification_labels_mapping[1:]]

  #get h_names from hierarchy csv
  h_names = [line[-1] for line in hierarchies]

  #create mapping from classification index to hierarchy index
  c2h_index_map = [h_names.index(i) for i in c_names]

  #create mapping from hierarchy index to classification index
  h2c_index_map = [c_names.index(i) if i in c_names else "undef" for i in h_names]
  return(hierarchies, c_names, h_names, c2h_index_map, h2c_index_map)

#Create json tree of hierarchy (list of dictionaries)

def get_node_object (name,h_names,hierarchies):  
  parent_index = None
  children_set = set()
  level = 0
  for line in hierarchies:
    if name in line:
      level = line.index(name)
      if parent_index == None:
        parent_index = h_names.index(line[level - 1])
      if level != len(line)-1:
        children_set.update([h_names.index(line[level + 1])])

  node_object = {
      "parent" : parent_index,
      "children" : list(children_set),
      "level" : level
  }
  return node_object

def get_hierarchy_tree(h_names,hierarchies):
  result = [get_node_object(h_name, h_names,hierarchies) for h_name in h_names]
  return result

"""Helper functions"""

def get_c_index(h_index):
  return h2c_index_map[h_index]
def get_h_index(c_index):
  return c2h_index_map[c_index]
def get_children(h_index):
  if type(h_index) == list:
    #Multiple children requests
    children = set()
    [children.update(h_tree[h_index_item]["children"]) for h_index_item in h_index]
    return list(children)
  else:
    return h_tree[h_index]["children"]
def get_parent(h_index):
  return h_tree[h_index]["parent"]
def get_level(h_index):
  return h_tree[h_index]["level"]

def get_h_names(h_index):
  if type(h_index) == list:
    #return names for list
    return [h_names[h] for h in h_index]
  else:
    return h_names[h_index]
    
def get_c_names(c_index):
  if type(c_index) == list:
    #return names for list
    return [c_names[c] for c in c_index]
  else:
    return c_names[c_index]

def get_confidence_sum(h_index_list,confidence_vector):
  if type(h_index_list) != list:
    h_index_list = [h_index_list]
  c_index_list = [get_c_index(h) for h in h_index_list]
  confidences = [confidence_vector[c] for c in c_index_list if c != "undef"]
  return sum(confidences)

def get_descendants(h_index):
  descendants = set()
  new_descendants = get_children(h_index)
  descendants.update(new_descendants)
  last_len_desc = 0
  while len(descendants) != last_len_desc:
    last_len_desc = len(descendants)
    new_descendants = get_children(new_descendants)
    descendants.update(new_descendants)
  return list(descendants)

def get_ancestors(h_index):
  ancestors = []
  x = h_index
  while x >0:
    x = get_parent(x)
    ancestors.append(x)
  return ancestors

#Create class lists to quickly calculate confidences
def get_relevant_h_classes(h_index, spec_level):
  if spec_level == 0:
    result_list = get_descendants(h_index)
    result_list.append(h_index)
  if spec_level >= 1:
    result_set = set()
    h_index_ref = h_index
    limit = min(spec_level, get_level(h_index))
    for i in range(limit):
      h_index_ref = get_parent(h_index_ref)
    result_set.update(get_descendants(h_index_ref))
    result_set.update([h_index,h_index_ref])
    result_list = list(result_set)
  return result_list

def write_relevant_classes_list(c_names,h_names):
  relevant_classes = []
  for c, name in enumerate(c_names):
    relevant_classes_in_level_list = []
    for i in range(8):
      relevant_classes_in_level = get_relevant_h_classes(get_h_index(c),i)
      relevant_classes_in_level_list.append(relevant_classes_in_level)
      if len(relevant_classes_in_level) == len(h_names):
        break
    relevant_classes.append(relevant_classes_in_level_list)
  
  relevant_classes = clean_relevant_classes(relevant_classes, c2h_index_map)
  return relevant_classes

def clean_relevant_classes(relevant_classes, c2h_index_map):
  #Remove all classes from relevant_classes, that are not in the dataset
  result = [[[ item for item in b if item in c2h_index_map ] for b in a] for a in relevant_classes]
  return result

def get_hierarchy_structure(c_names, c2h_index_map):
  result_index = [[get_h_index(c_index) for c_index in range(len(c_names)) if get_level(get_h_index(c_index)) == level] for level in range(8)]
  result_classes = []
  for l in result_index:
    result_classes_level =[]
    for h in l:
      new_items = get_relevant_h_classes(h,0)
      result_classes_level.append([item for item in new_items if item in c2h_index_map])
    result_classes.append(result_classes_level)
  return (result_index,result_classes)

def calculate_hierarchy_confidences(c_names, hierarchy_structure, confidence_vector):
  #SPEED PRIORITY
  result_confidences = []
  for l in hierarchy_structure:
    result_confidences_level =[]
    for h in l:
      result_confidences_level.append(get_confidence_sum(h,confidence_vector))
    result_confidences.append(result_confidences_level)
  return result_confidences

def get_result(confidence_vector, probability_threshold):
  hierarchy_confidences = calculate_hierarchy_confidences(c_names,hierarchy_structure, confidence_vector)
  for i,level in enumerate(reversed(hierarchy_confidences)):
    if level:
      if max(level) >= probability_threshold:
        result = hierarchy_names_structure[7-i][np.argmax(level)]
        return result
  return 0

#Initialize global variables
def initialize_variables(config):
  hierarchies, c_names, h_names, c2h_index_map, h2c_index_map = load_files(config)
  h_tree = get_hierarchy_tree(h_names,hierarchies)
  return hierarchies, c_names, h_names, c2h_index_map, h2c_index_map, h_tree

#Initialize hierarchy structur
def initialize_structure():
  hierarchy_names_structure, hierarchy_structure = get_hierarchy_structure(c_names, c2h_index_map)
  return  hierarchy_names_structure, hierarchy_structure

"""Prediction functions"""

def get_confusion_matrix (c_groundtruth, confidence_vectors,threshold):
  h_predictions = get_predictions(confidence_vectors,threshold)
  h_groundtruth,_,_ = recalculate_groundtruth(c_groundtruth,h_predictions) 
  confusion_m = confusion_matrix(h_groundtruth,h_predictions)
  accuracy = accuracy_score(h_groundtruth,h_predictions)
  return confusion_m, accuracy

def get_metrics (c_groundtruth, confidence_vectors,threshold):
  h_predictions = get_predictions(confidence_vectors,threshold)
  h_groundtruth, avg_level_diff, level_diff_stats, level_stats = recalculate_groundtruth(c_groundtruth,h_predictions)
  clean_h_groundtruth, clean_h_predictions = remove_owl_thing(h_groundtruth,h_predictions)

  accuracy = accuracy_score(h_groundtruth,h_predictions)
  clean_accuracy = accuracy_score(clean_h_groundtruth,clean_h_predictions)
  no_owl_thing_perc = len(clean_h_predictions)/len(h_predictions)
  average_level = np.average([get_level(x) for x in clean_h_predictions])
  return accuracy, clean_accuracy, no_owl_thing_perc, avg_level_diff, average_level, level_diff_stats, level_stats

def get_predictions(confidence_vectors, threshold):
  h_predictions = [get_result(v,threshold) for v in confidence_vectors]
  return h_predictions

def recalculate_groundtruth(c_groundtruth,h_predictions):
  h_groundtruth = [get_h_index(c) for c in c_groundtruth]
  result = []
  total_level_diff = 0
  dividend = 0
  level_diff_stats = [0,0,0,0,0,0,0,0,0,0,0,0,0,0]
  level_stats = [0,0,0,0,0,0,0]
  for g,p in zip(h_groundtruth,h_predictions):
    ground_ancestors = get_ancestors(g)
    #Descendants not allowed in hierarchy-hits!
    #ground_descendants = get_descendants(g)
    ground_hierarchy = [g] + ground_ancestors #+ ground_descendants 
    
    normal_level = get_level(g)

    if p in ground_hierarchy:
      result.append(p)
      result_level = get_level(p)
    else:
      result.append(g)
      result_level = get_level(g)
    
    if result_level != 0:
      dividend += 1
      level_difference = normal_level - result_level
      total_level_diff = total_level_diff + level_difference
      level_diff_stats[level_difference] += 1
      level_stats[result_level] += 1

  avg_level_diff = total_level_diff/dividend
  return result, avg_level_diff, level_diff_stats, level_stats

def remove_owl_thing(h_groundtruth,h_predictions):
  g_result = []
  p_result = []
  for g,p in zip(h_groundtruth,h_predictions):
    if g != 0:
      g_result.append(g)
      p_result.append(p)
  return g_result,p_result

"""#Run"""

config = "config_5"
#Initialize global variables and structure
hierarchies, c_names, h_names, c2h_index_map, h2c_index_map, h_tree = initialize_variables(config)
hierarchy_names_structure, hierarchy_structure = initialize_structure()

"""#Evaluation
Create Confusion Matrix for evaluation dataset
"""

#csv_file_confs = csv_to_list("/content/drive/My Drive/ISE/confidences-2.csv")
#csv_file_labels = csv_to_list("/content/drive/My Drive/ISE/labels.csv")

csv_file_confs = csv_to_list("/content/drive/My Drive/ISE/confidences-3.csv")
csv_file_labels = csv_to_list("/content/drive/My Drive/ISE/labels-2.csv")

confidence_vectors = [[float(y) for y in x[1:]] for x in csv_file_confs[1:]]
c_groundtruth = [int(x[1:][0]) for x in csv_file_labels[1:]]
#get_confusion_matrix(c_groundtruth,confidence_vectors,0.9)
get_metrics(c_groundtruth,confidence_vectors,0.7)

"""Calculate plot data"""

results = []
for x in range(0, 100,5):
  x = x/100
  r = get_metrics(c_groundtruth,confidence_vectors,x)
  print("Threshold: " + str(np.round(x,2)))
  print("Accuracy: " + str(r[1]))
  print("% of data pred.: " + str(np.round(r[2],2)))
  print("Avg level: " + str(np.round(r[4],2)))
  print("Avg level difference: " + str(np.round(r[3],2)))
  print("level differencess: " + str(r[5]))
  print("level distribution: " + str(r[6]))
  print("")
  results.append([x] + list(r))

"""Plot over percentage-predicted"""

import matplotlib.patches as mpatches

rel_data_chris = [x[3] for x in results]
accs_chris = [x[2] for x in results]
rel_data_chris = [x[3] for x in results]
lvls_chris = [x[4] for x in results]
annotations_chris = [np.round(x[0],2) for x in results]

rel_data = [1.0,
 0.9997639728096677,
 0.9682071374622356,
 0.87266333081571,
 0.7585677870090635,
 0.654007741691843,
 0.5646242447129909,
 0.48302964501510576,
 0.41446374622356497,
 0.3526482250755287,
 0.29793712235649544,
 0.2539652567975831,
 0.2185375755287009,
 0.1893174093655589,
 0.16172583081570996,
 0.123985083081571,
 0.09611027190332326,
 0.06884913141993958,
 0.04222526435045317,
 0.012580249244712991]
accs = [0.4015530589123867,
 0.40164785872798525,
 0.41244728309890055,
 0.44416195602196196,
 0.48234232552350725,
 0.5245588076076365,
 0.5642086782041635,
 0.6045443440019546,
 0.6406036446469249,
 0.6774646944648952,
 0.7124296918323695,
 0.7467472118959108,
 0.7782697915541635,
 0.800772970951253,
 0.8279334500875657,
 0.8509423186750429,
 0.8705795677799607,
 0.89681179293795,
 0.9122414756847401,
 0.9230769230769231]
rel_data_lvl1 = [1.0,
 1.0,
 1.0,
 0.9999527945619335,
 0.99766333081571,
 0.9905353096676737,
 0.9771997734138973,
 0.9598753776435045,
 0.934054003021148,
 0.9032524546827795,
 0.8682260196374623,
 0.8320666540785498,
 0.7933581948640483,
 0.7531627643504532,
 0.7068542296072508,
 0.6493816087613293,
 0.5727671827794562,
 0.4527709592145015,
 0.2790313444108761,
 0.08150018882175226]
accs_lvl1 = [0.8101161253776435,
 0.8101161253776435,
 0.8101161253776435,
 0.8101543690695369,
 0.81163500437673,
 0.8157600019062596,
 0.8232452538524709,
 0.8321038654470345,
 0.8442917066761004,
 0.8577699966029946,
 0.872366453717548,
 0.8859671517317675,
 0.898908160533127,
 0.9102475712942651,
 0.9214972619206625,
 0.9321775160833061,
 0.9446985618329419,
 0.9562633581817234,
 0.9686178311622399,
 0.9774109470026064]
annotations = [x/100 for x in list(range(0,100,5))]

fig, ax1 = plt.subplots(figsize=(20,10)) 
plt.xlabel('% of data predicted')
plt.ylabel('prediction accuracy')   
plt.grid(b=True, which='major', color='#e3e3e3', linestyle='-')  

ax1.plot(rel_data,accs,".-r", label="prediction on all entity levels")
ax1.plot(rel_data_lvl1,accs_lvl1,".-b",label="prediction on top entity level")
ax1.plot(rel_data_chris,accs_chris,".-g",label="prediction with specific levels")
ax1.set_xlim(1.05, -0.05) 
plt.xticks(np.arange(0, 1.1, step=0.1))
leg = ax1.legend(loc='upper left');
extraString = 'confidence threshold'
handles, labels = ax1.get_legend_handles_labels()

ax2 = ax1.twinx()
ax2.set_ylabel('average level-difference', color="g")
ax2.plot(rel_data_chris,lvls_chris,".-g",linestyle="dotted",label="Average level-diff of prediction")
ax2.plot([0,1],[1.97,1.97],".-g",linestyle="dotted",label="Average level-diff of prediction")
ax2.tick_params(axis='y', labelcolor="g")
#leg2 = ax2.legend(loc='upper right');

handles.append(mpatches.Patch(color='none', label=extraString))
plt.legend(handles=handles)
for index,annotation in enumerate(annotations):
  if (index+1) % 2 == 0:
    ax1.text(rel_data[index]+0.01, accs[index]+0.005,annotation,va="bottom")
    ax1.text(rel_data_lvl1[index]+0.01, accs_lvl1[index]+0.005,annotation,va="bottom")
for index,annotation in enumerate(annotations_chris):
  if (index+1) % 2 == 0:
    ax1.text(rel_data_chris[index]+0.01, accs_chris[index]+0.005,annotation,va="bottom")